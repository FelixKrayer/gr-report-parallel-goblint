\section{Introduction}
\label{sec:introduction}
% Copied and slightly adapted from project description.
Static analyzers examine the source code of a program to find semantic properties without having to execute it. To gain information about a program, many analyzers compute abstract values for the different program points that over-approximate the set of possible concrete states. This is done by generating a system of constraints, where the unknowns are program points, possibly together with some calling context. The instructions in the code give rise to constraints describing how they affect the abstract state. When the system of constraints is generated, the analyzer solves it for a solution through fix-point iteration. This means that from an initial non-satisfying assignment of values to unknowns, these values are updated according to the constraints until a fix-point is reached, and all constraints are satisfied. Well-known algorithms for fix-point iteration are round-robin iteration and the work-list algorithm. Round-robin algorithms can, however, only be used for finite constraint systems and the work-list algorithm usually requires static dependencies. In contrast, the top-down solver recursively explores a possibly infinite constraint system on demand and tracks dynamic dependencies on the fly. It aims to find solutions for a defined set of interesting unknowns, e.g., an end node of the main program. For that, it recursively evaluates stable values for unknowns that are needed to compute the values for the set of interesting ones. If the value for a stable unknown is needed, it can just be looked up and does not have to be calculated again. However, if a new value for an unknown is computed and updated during the solving process, it is necessary to destabilize all unknowns that depend on this updated unknown. This means that the values for the now destabilized unknowns have to be evaluated again as they have to factor in the new value of the updated unknown. These dependencies of unknowns are detected dynamically during the solving process and are saved in a data structure. Further data structures are used to keep track of stable unknowns and their values. 
The time of analysis grows together with program size. For example, an analysis of SQL lite 3 takes multiple hours with the \gob\ static analyzer. A significant part of the overall analysis time is spent by the solver on finding a solution for the constraint system. Thus, improving the performance of a solver with respect to computation time seems a promising way to improve the speed of the whole analysis. An idea to approach this issue is to equip the top-down solver with a way to execute tasks in parallel and find steps of the solving process, where a speedup can likely be achieved through parallelization. For example, an unknown can depend on multiple other unknowns, e.g., when a thread is created and the thread function has to be analyzed as well as the rest of the program. In this case, one can imagine, that stable values for the unknowns corresponding to the thread function could be computed parallel to the unknowns corresponding to the main program, and the computation time could be reduced.
As our main contribution, we aim to implement a parallelized top-down solver for the \gob\ analyzer.

This report is structured as follows: In~\autoref{sec:background} we introduce side-effecting constraint systems as they are used in \gob\ and explain how a single-threaded top-down solver works. In~\autoref{sec:method} we present our contributions. We explain, how we adapt the constraint system to indicate for which unknowns parallelized solving can be useful. Furthermore, we implement a thread-safe data structure in this section. In~\autoref{sec:method:td_parallel} we present three different concepts of parallelized solvers and implement them in \gob\ as our main contribution. We evaluate our implementation by comparing the runtimes of the solvers in~\autoref{sec:eval}. Lastly we give our conclusions and ideas for future work in~\autoref{sec:conclusions} 
